{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f06437d",
   "metadata": {},
   "source": [
    "In this notebook, I launched 6 fine-tuning jobs, experimenting with: \n",
    "- 2 types of instructions, with very different levels of verbosity \n",
    "    - simple instruction: \"\"\"Given the following Airbnb description, Extract the number of bedrooms, determine the type of property, \n",
    "            determine whether Is any space shared?, and classify Overall vibes/atmosphere \n",
    "            return in JSON format:\"\"\"\n",
    "    - the detailed instruction, not included for space consideration, is highly detailed. It is the same instruction previously provided to\n",
    "    annotator (in this case, gpt4) to obtain the labels. \n",
    "    Explanation: expected benefits of more detailed instructions are that model understands correctly context, nuances and rules but\n",
    "    length of instructions have implications on compute time  and costs (higher token count)\n",
    "- 3 models which entail different data preparation, cost and expected performance \n",
    "    - babbage-02: smaller and faster model suitable for tasks requiring less understanding of complex contexts. Ideal for cost-effective training and inference.\n",
    "    - davinci-02: more capable model, excellent for handling nuanced and complex tasks --> might be overkill for our domain (i.e airbnb listings)\n",
    "    - gpt-3.5-turbo: balances performance and cost, providing a good compromise between the capabilities of Davinci and the efficiency of Babbage.\n",
    "- hyperparameter turning:\n",
    "    - n_epoch = 3 (default to auto, which ends up being 3)\n",
    "    - n_epoch = 4\n",
    "    Explanation: openai specifies there are 3 hyperparams we can tinker with for the finetuning process, i.e. n_epochs, learning_rate, batch_size.\n",
    "    I chose to try two different n_epochs for 2 reasons:, \n",
    "    1) I noticed the results from earlier fine tuning that the generated text didn't comply with desired structured format\n",
    "    2) so I looked for openai suggestions, which states \"If the model does not follow the training data as much as expected increase the number of epochs by 1 or 2\n",
    "    This is more common for tasks for which there is a single ideal completion\" --> which is our case. Risk of high epochs: overfitting. \n",
    "    As for learning rate and batch size, adjusting them having effects on training speed (higher in both cases) but may have poor effects on performance due to skipping \n",
    "    over optimal solutions (learning rate) or stable gradient estimates (batch size) --> in our context, it is safe to leave these to default options.\n",
    "\n",
    "#### fine_tuning_data_v2 (less detailed instructions) n_epochs = 4\n",
    "- model = babbage-02\n",
    "- n_epochs = 4\n",
    "- training_file 'file-4s2gV7Ns8onjSGCOICgoEdEF'\n",
    "- validation_file 'file-I1PF9wqVH2PHm3pWPyNU7G58'\n",
    "- fine-tuning_job 'ftjob-ZSkRid0H4hbSl3hYC2LcphOe'\n",
    "- trained tokens 224,300\n",
    "- model_name = 'ft:babbage-002:personal::9tf9RTDu'\n",
    "#### fine_tuning_data_v2_detailedInstructions (detailed instructions) n_epochs = 4\n",
    "- model = babbage-02\n",
    "- n_epochs = 4\n",
    "- training_file 'file-Eiy3m0qnaff0VmGx78Ran3Yh'\n",
    "- validation_file 'file-sK8gNy3mUGioA7ai7UtAl3MO'\n",
    "- fine-tuning_job 'ftjob-7ad6DlW1d9g4IEdNkMzzzODa'\n",
    "- trained_tokens = 785,900\n",
    "- model_name = 'ft:babbage-002:personal::9tf9VhUQ'\n",
    "\n",
    "#### fine_tuning_data_v2 (less detailed instructions) n_epochs = 3\n",
    "- model = babbage-02\n",
    "- n_epochs = 3\n",
    "- training_file 'file-4s2gV7Ns8onjSGCOICgoEdEF'\n",
    "- validation_file 'file-I1PF9wqVH2PHm3pWPyNU7G58'\n",
    "- fine-tuning_job 'ftjob-tQoI8kM7DzuEqW8xN1tqF8R2'\n",
    "- trained_tokens 168,225\n",
    "- model_name = 'ft:babbage-002:personal::9tg6PCpn'\n",
    "\n",
    "#### fine_tuning_data_v2_detailedInstructions (detailed instructions) n_epochs = 3\n",
    "- model = babbage-02\n",
    "- n_epochs = 3\n",
    "- training_file 'file-Eiy3m0qnaff0VmGx78Ran3Yh'\n",
    "- validation_file 'file-sK8gNy3mUGioA7ai7UtAl3MO'\n",
    "- fine-tuning_job 'ftjob-banNk4hagWP3Xy8eQyjjsu79'\n",
    "- model_name =  'ft:babbage-002:personal::9tg8SIK0'\n",
    "\n",
    "#### fine_tuning_data_v2_detailedInstructions (detailed instructions) n_epochs = 3\n",
    "- model = davinci-02\n",
    "- n_epochs = 3\n",
    "- training_file 'file-Eiy3m0qnaff0VmGx78Ran3Yh'\n",
    "- validation_file 'file-sK8gNy3mUGioA7ai7UtAl3MO'\n",
    "- fine-tuning_job 'ftjob-BGng5tnE2JQpUr2sAQXP8kzf'\n",
    "- model_name = 'ft:davinci-002:personal::9tgOuHsg'\n",
    "\n",
    "#### fine_tuning_data_v2_detailedInstructions (detailed instructions) n_epochs = 3\n",
    "- model = turbo-3.5-turbo\n",
    "- n_epochs = 3\n",
    "- training_file 'file-V4lt8WdWRyXaI03BlmSGv6Ar'\n",
    "- validation_file 'file-N2WqIogEUy228sRTnGlivbMG'\n",
    "- fine-tuning_job 'ftjob-6DRxt0SWJAA0gjLuZXzFkw4h'\n",
    "- trained_tokens 603,678\n",
    "- model_name = 'ft:gpt-3.5-turbo-0125:personal::9tg6PAnc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d2d8c3bf-a9f5-474c-8f08-0c5b43cc0248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T06:22:28.925569Z",
     "iopub.status.busy": "2024-08-08T06:22:28.924192Z",
     "iopub.status.idle": "2024-08-08T06:22:28.954039Z",
     "shell.execute_reply": "2024-08-08T06:22:28.953338Z",
     "shell.execute_reply.started": "2024-08-08T06:22:28.925492Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6acb59e3-6ec7-484e-9812-f2c2ced6cfc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T17:44:17.231496Z",
     "iopub.status.busy": "2024-08-07T17:44:17.230853Z",
     "iopub.status.idle": "2024-08-07T17:44:28.581106Z",
     "shell.execute_reply": "2024-08-07T17:44:28.578448Z",
     "shell.execute_reply.started": "2024-08-07T17:44:17.231454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At directory fine_tuning_data_v2 \n",
      " training_file FileObject(id='file-4s2gV7Ns8onjSGCOICgoEdEF', bytes=277527, created_at=1723052658, filename='train.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None) \n",
      " validation_file FileObject(id='file-I1PF9wqVH2PHm3pWPyNU7G58', bytes=93709, created_at=1723052659, filename='val.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None) \n",
      " and finetuning job FineTuningJob(id='ftjob-ZSkRid0H4hbSl3hYC2LcphOe', created_at=1723052663, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=4, batch_size='auto', learning_rate_multiplier='auto'), model='babbage-002', object='fine_tuning.job', organization_id='org-XDNeT4rDqlxhjhHN3y4zZbkA', result_files=[], seed=1734117511, status='validating_files', trained_tokens=None, training_file='file-4s2gV7Ns8onjSGCOICgoEdEF', validation_file='file-I1PF9wqVH2PHm3pWPyNU7G58', integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
      "At directory fine_tuning_data_v2_detailedInstructions \n",
      " training_file FileObject(id='file-Eiy3m0qnaff0VmGx78Ran3Yh', bytes=983127, created_at=1723052664, filename='train.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None) \n",
      " validation_file FileObject(id='file-sK8gNy3mUGioA7ai7UtAl3MO', bytes=328909, created_at=1723052665, filename='val.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None) \n",
      " and finetuning job FineTuningJob(id='ftjob-7ad6DlW1d9g4IEdNkMzzzODa', created_at=1723052668, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=4, batch_size='auto', learning_rate_multiplier='auto'), model='babbage-002', object='fine_tuning.job', organization_id='org-XDNeT4rDqlxhjhHN3y4zZbkA', result_files=[], seed=519805145, status='validating_files', trained_tokens=None, training_file='file-Eiy3m0qnaff0VmGx78Ran3Yh', validation_file='file-sK8gNy3mUGioA7ai7UtAl3MO', integrations=[], user_provided_suffix=None, estimated_finish=None)\n"
     ]
    }
   ],
   "source": [
    "directories = ['fine_tuning_data_v2', 'fine_tuning_data_v2_detailedInstructions']\n",
    "\n",
    "for directory in directories:\n",
    "    training_file = client.files.create(\n",
    "      file=open(f\"{directory}/train.jsonl\", \"rb\"),\n",
    "      purpose=\"fine-tune\"\n",
    "    )\n",
    "    \n",
    "    validation_file = client.files.create(\n",
    "      file=open(f\"{directory}/val.jsonl\", \"rb\"),\n",
    "      purpose=\"fine-tune\"\n",
    "    )\n",
    "\n",
    "    fine_tuning_job = client.fine_tuning.jobs.create(\n",
    "      training_file=training_file.id,\n",
    "      validation_file=validation_file.id, \n",
    "      model=\"babbage-002\",\n",
    "        hyperparameters={\n",
    "        \"n_epochs\":4\n",
    "      }\n",
    ")\n",
    "\n",
    "    print(f'At directory {directory} \\n training_file {training_file} \\n validation_file {validation_file} \\n and finetuning job {fine_tuning_job}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "85f7239c-0649-419d-b013-24dad153b6bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T18:47:43.542277Z",
     "iopub.status.busy": "2024-08-07T18:47:43.541078Z",
     "iopub.status.idle": "2024-08-07T18:47:46.114982Z",
     "shell.execute_reply": "2024-08-07T18:47:46.114214Z",
     "shell.execute_reply.started": "2024-08-07T18:47:43.542224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-tQoI8kM7DzuEqW8xN1tqF8R2', created_at=1723056465, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='babbage-002', object='fine_tuning.job', organization_id='org-XDNeT4rDqlxhjhHN3y4zZbkA', result_files=[], seed=595555851, status='validating_files', trained_tokens=None, training_file='file-4s2gV7Ns8onjSGCOICgoEdEF', validation_file='file-I1PF9wqVH2PHm3pWPyNU7G58', integrations=[], user_provided_suffix=None, estimated_finish=None)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we're gonna run this again with no changes to the hyperparams n_epochs\n",
    "\n",
    "# for fine_tuning_data_v2\n",
    "fine_tuning_job = client.fine_tuning.jobs.create(\n",
    "  training_file='file-4s2gV7Ns8onjSGCOICgoEdEF',\n",
    "  validation_file='file-I1PF9wqVH2PHm3pWPyNU7G58', \n",
    "  model=\"babbage-002\",\n",
    "    )\n",
    "fine_tuning_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5c58b0e6-90a9-43a2-bb46-d56934d5d9aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T18:49:48.790651Z",
     "iopub.status.busy": "2024-08-07T18:49:48.789427Z",
     "iopub.status.idle": "2024-08-07T18:49:52.386227Z",
     "shell.execute_reply": "2024-08-07T18:49:52.384959Z",
     "shell.execute_reply.started": "2024-08-07T18:49:48.790592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-banNk4hagWP3Xy8eQyjjsu79', created_at=1723056592, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='babbage-002', object='fine_tuning.job', organization_id='org-XDNeT4rDqlxhjhHN3y4zZbkA', result_files=[], seed=1674744380, status='validating_files', trained_tokens=None, training_file='file-Eiy3m0qnaff0VmGx78Ran3Yh', validation_file='file-sK8gNy3mUGioA7ai7UtAl3MO', integrations=[], user_provided_suffix=None, estimated_finish=None)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#detailed instructions\n",
    "\n",
    "fine_tuning_job = client.fine_tuning.jobs.create(\n",
    "  training_file='file-Eiy3m0qnaff0VmGx78Ran3Yh',\n",
    "  validation_file='file-sK8gNy3mUGioA7ai7UtAl3MO', \n",
    "  model=\"babbage-002\",\n",
    "    )\n",
    "fine_tuning_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4252b5d1-85a2-4a50-86f3-fc6bd6be772d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T19:03:53.777740Z",
     "iopub.status.busy": "2024-08-07T19:03:53.776622Z",
     "iopub.status.idle": "2024-08-07T19:03:56.899010Z",
     "shell.execute_reply": "2024-08-07T19:03:56.897490Z",
     "shell.execute_reply.started": "2024-08-07T19:03:53.777669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-BGng5tnE2JQpUr2sAQXP8kzf', created_at=1723057436, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='davinci-002', object='fine_tuning.job', organization_id='org-XDNeT4rDqlxhjhHN3y4zZbkA', result_files=[], seed=339862684, status='validating_files', trained_tokens=None, training_file='file-Eiy3m0qnaff0VmGx78Ran3Yh', validation_file='file-sK8gNy3mUGioA7ai7UtAl3MO', integrations=[], user_provided_suffix=None, estimated_finish=None)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#detailed instructions\n",
    "fine_tuning_job = client.fine_tuning.jobs.create(\n",
    "  training_file='file-Eiy3m0qnaff0VmGx78Ran3Yh',\n",
    "  validation_file='file-sK8gNy3mUGioA7ai7UtAl3MO', \n",
    "  model=\"davinci-002\",\n",
    "    )\n",
    "fine_tuning_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7c75c30-3b92-4ba4-b102-5ddac6b3a960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T18:18:42.124968Z",
     "iopub.status.busy": "2024-08-07T18:18:42.124243Z",
     "iopub.status.idle": "2024-08-07T18:18:48.345649Z",
     "shell.execute_reply": "2024-08-07T18:18:48.343925Z",
     "shell.execute_reply.started": "2024-08-07T18:18:42.124919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At directory fine_tuning_data_v2_detailedInstructions_gpt3format \n",
      " training_file FileObject(id='file-V4lt8WdWRyXaI03BlmSGv6Ar', bytes=1009407, created_at=1723054723, filename='train.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None) \n",
      " validation_file FileObject(id='file-N2WqIogEUy228sRTnGlivbMG', bytes=337669, created_at=1723054725, filename='val.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None) \n",
      " and finetuning job FineTuningJob(id='ftjob-6DRxt0SWJAA0gjLuZXzFkw4h', created_at=1723054728, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-XDNeT4rDqlxhjhHN3y4zZbkA', result_files=[], seed=201651482, status='validating_files', trained_tokens=None, training_file='file-V4lt8WdWRyXaI03BlmSGv6Ar', validation_file='file-N2WqIogEUy228sRTnGlivbMG', integrations=[], user_provided_suffix=None, estimated_finish=None)\n"
     ]
    }
   ],
   "source": [
    "directories = ['fine_tuning_data_v2_detailedInstructions_gpt3format']\n",
    "\n",
    "for directory in directories:\n",
    "    training_file = client.files.create(\n",
    "      file=open(f\"{directory}/train.jsonl\", \"rb\"),\n",
    "      purpose=\"fine-tune\"\n",
    "    )\n",
    "    \n",
    "    validation_file = client.files.create(\n",
    "      file=open(f\"{directory}/val.jsonl\", \"rb\"),\n",
    "      purpose=\"fine-tune\"\n",
    "    )\n",
    "\n",
    "    fine_tuning_job = client.fine_tuning.jobs.create(\n",
    "      training_file=training_file.id,\n",
    "      validation_file=validation_file.id, \n",
    "      model=\"gpt-3.5-turbo\"\n",
    "      \n",
    ")\n",
    "\n",
    "    print(f'At directory {directory} \\n training_file {training_file} \\n validation_file {validation_file} \\n and finetuning job {fine_tuning_job}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12f67f93-c395-4457-874f-311595fc2f04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T14:21:10.033523Z",
     "iopub.status.busy": "2024-08-07T14:21:10.033344Z",
     "iopub.status.idle": "2024-08-07T14:21:11.024609Z",
     "shell.execute_reply": "2024-08-07T14:21:11.023144Z",
     "shell.execute_reply.started": "2024-08-07T14:21:10.033509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(id='cmpl-9tbpGITL45DwcP8jG8m1rdmRROKe9', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text=' <br /><br />The apartment is on the 2nd floor of a 3 story building. <br /><br />The apartment is on the 2nd floor of a 3 story building. <br /><br />The apartment is on the 2nd floor of a 3 story building. <br /><br />The apartment is on the 2nd floor of a 3 story building. <br /><br />The apartment is on the 2nd floor of a 3 story building. <br /><br />The apartment is on the 2nd floor of a 3 story building. <br /><br />The apartment is on the 2nd floor of a 3 story building. <br /><')], created=1723040470, model='babbage-002', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=150, prompt_tokens=91, total_tokens=241))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.completions.create(\n",
    "  model=\"babbage-002\",\n",
    "  prompt=\"One of a kind studio apartment in the best Chelsea location. <br /><br />This recently renovated studio apartment is stunning, modern, and well appointed. With a double bed upstairs, a living room and kitchenette downstairs, the bathroom is outside of the apartment in the hallway and shared with one other tenant. <br /><br />Located in a quiet residential building facing the rear, but centrally located near the subway and all the best shopping and restaurants.\",\n",
    "  max_tokens=150,\n",
    "  temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "620c9d91-f983-41c2-8ec1-7d15acdc3e4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T04:53:38.116456Z",
     "iopub.status.busy": "2024-08-08T04:53:38.115364Z",
     "iopub.status.idle": "2024-08-08T04:53:38.133640Z",
     "shell.execute_reply": "2024-08-08T04:53:38.132926Z",
     "shell.execute_reply.started": "2024-08-08T04:53:38.116395Z"
    }
   },
   "outputs": [],
   "source": [
    "def call_model(model, prompt, max_tokens=150, temperature=0):\n",
    "\n",
    "    return client.completions.create(\n",
    "      # model=\"ft:babbage-002:personal::9tbdQSFF\",\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        frequency_penalty=0,  # Reduce likelihood of repetition\n",
    "        presence_penalty=0,   # No need to introduce new topics\n",
    "        stop=[\"}\"],          # Stop generating after two new lines\n",
    "    )\n",
    "    \n",
    "def create_default_data():\n",
    "    # This returns a defaultdict that defaults to \"Not Present\" for missing keys\n",
    "    return defaultdict(lambda: \"Not Present\")\n",
    "\n",
    "\n",
    "def fix_and_complete_json(raw_json):\n",
    "    try:\n",
    "        # Find the last valid comma and cut the string there\n",
    "        last_valid_comma = raw_json.rfind(',')\n",
    "        if last_valid_comma > -1:\n",
    "            clean_json = raw_json[:last_valid_comma] + \"}\"\n",
    "        else:\n",
    "            clean_json = raw_json\n",
    "\n",
    "        # Attempt to load it as JSON to see if it is valid\n",
    "        data = json.loads(clean_json)\n",
    "        return data\n",
    "    except json.JSONDecodeError:\n",
    "        # If still failing, return a message or handle the case as needed\n",
    "        return \"Failed to decode JSON.\"\n",
    "\n",
    "\n",
    "def clean_raw_output(raw_output):\n",
    "    if not raw_output:\n",
    "        print(\"Warning: No output received.\")\n",
    "        return None\n",
    "        \n",
    "    # Clean up unexpected characters\n",
    "    clean_output = raw_output.replace('\">', '')\n",
    "\n",
    "    #Find the last valid comma and cut the string there\n",
    "    last_valid_comma = raw_output.rfind(',')\n",
    "    if last_valid_comma > -1:\n",
    "        clean_json = raw_output[:last_valid_comma] + \"}\"\n",
    "    else:\n",
    "        clean_json = raw_output\n",
    "\n",
    "    return clean_json\n",
    "\n",
    "def load_clean_json(clean_json):\n",
    "    # Parse the JSON data\n",
    "    return json.loads(clean_json)\n",
    "\n",
    "def parse_output_json(data):\n",
    "        \n",
    "    # Prepare a default data container with expected keys defaulted to \"Not Present\"\n",
    "    default_data = create_default_data()\n",
    "    default_data.update(data)  # Update with actual data\n",
    "    \n",
    "    # Extract only the expected keys\n",
    "    expected_keys = [\"Number of Bedrooms\", \"Type of Property\", \"Is the space shared?\", \"Overall vibe\"]\n",
    "    validated_data = {key: default_data[key] for key in expected_keys}\n",
    "    \n",
    "    return validated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "01908bb9-f9cd-4464-b480-f24285c86022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T04:53:38.381334Z",
     "iopub.status.busy": "2024-08-08T04:53:38.380486Z",
     "iopub.status.idle": "2024-08-08T04:53:38.392326Z",
     "shell.execute_reply": "2024-08-08T04:53:38.390935Z",
     "shell.execute_reply.started": "2024-08-08T04:53:38.381273Z"
    }
   },
   "outputs": [],
   "source": [
    "# # model = \"ft:babbage-002:personal::9tf9VhUQ\" #detailed instructions\n",
    "# # model = 'ft:babbage-002:personal::9tf9RTDu' #less instruction\n",
    "# # model = 'ft:babbage-002:personal::9tbdQSFF' #different-ish data\n",
    "# # model = 'ft:gpt-3.5-turbo-0125:personal::9tg6PAnc' #3.5 turbo on detailed instructions\n",
    "# # model = 'ft:babbage-002:personal::9tg6PCpn'\n",
    "# model = 'ft:davinci-002:personal::9tgOuHsg'\n",
    "# # prompt = \"\"\"\n",
    "# # Stunning designer Chelsea studio on the best block\tOne of a kind studio apartment in the best Chelsea location. <br /><br />This recently renovated studio apartment is stunning, modern, and well appointed. With a double bed upstairs, a living room and kitchenette downstairs, the bathroom is outside of the apartment in the hallway and shared with one other tenant. <br /><br />Located in a quiet residential building facing the rear, but centrally located near the subway and all the best shopping and restaurants.\n",
    "# # \"\"\"\n",
    "# # prompt = \"\"\"\n",
    "# # extract 4 features from airbnb listing and return response in json format: Bright 2 Bedroom in Astoria\tBright and airy 2 bedroom, steps from Ditmars Blvd N/W train. 5th Floor walkup with roof access and stunning views of NYC.\n",
    "# # \"\"\"\n",
    "# prompt = \"\"\"\n",
    "# Welcome to your perfect Brooklyn retreat! Fully furnished studio/junior 1-bedroom apartment in Fort Greene / Clinton Hill only 2 minutes from the C train, 8 minutes from the G train and 10 minutes from Atlantic/Barclays.<br /><br />Apt is in a luxury building with amenities such as a fully equipped kitchen with dishwasher, in-unit washer-dryer, and more. Enjoy a comfortable stay with modern furnishings and all the essentials you need.<br /><br />Please message with a bit info about yourself if interested!\n",
    "# \"\"\"\n",
    "\n",
    "# completion = call_model(model, prompt, max_tokens=50, temperature=0.5)\n",
    "# raw_output = completion.choices[0].text\n",
    "# clean_json = clean_raw_output(raw_output)\n",
    "data = load_clean_json(clean_json)\n",
    "validated_data = parse_output_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "eaa1671d-8968-49df-9797-700dea97fc9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T04:53:43.946916Z",
     "iopub.status.busy": "2024-08-08T04:53:43.945894Z",
     "iopub.status.idle": "2024-08-08T04:53:43.954555Z",
     "shell.execute_reply": "2024-08-08T04:53:43.953430Z",
     "shell.execute_reply.started": "2024-08-08T04:53:43.946875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Number of Bedrooms': '1',\n",
       " 'Type of Property': 'Apartment',\n",
       " 'Is the space shared?': 'Not Present',\n",
       " 'Overall vibe': 'Not Present'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fb153bb8-ef0e-4e43-ae15-9598d3230dff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T04:53:53.127153Z",
     "iopub.status.busy": "2024-08-08T04:53:53.126310Z",
     "iopub.status.idle": "2024-08-08T04:53:53.137781Z",
     "shell.execute_reply": "2024-08-08T04:53:53.136383Z",
     "shell.execute_reply.started": "2024-08-08T04:53:53.127089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Number of Bedrooms\": \"1\", \"Type of Property\": \"Apartment\", \"Is any space shared?\": \"FALSE\", \"Overall condition of the property\": \"MODERN\"}'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
